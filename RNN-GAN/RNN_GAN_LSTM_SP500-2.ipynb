{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e01218b8",
      "metadata": {
        "id": "e01218b8"
      },
      "source": [
        "\n",
        "# RNN-GAN (LSTM) — Génération de séries temporelles du S&P 500\n",
        "\n",
        "**Objectif :** entraîner un WGAN-GP avec un générateur et un critique LSTM pour générer des **rendements** puis tracer des **courbes de prix** synthétiques, et comparer des **statistiques clés** entre série réelle et synthétique **à la fin de 150 epochs**.\n",
        "\n",
        "**Points clés :**\n",
        "- Données : `^GSPC` via `yfinance` (depuis 1990).\n",
        "- Prétraitement : log-rendements, normalisation avec **stats d'entraînement** (pas de fuite d'info).\n",
        "- Modèle : WGAN-GP (LSTM Generator + LSTM Critic avec pooling temporel).\n",
        "- Hyperparamètres (par défaut) : `nz=100`, `epochs=150`, `lr_G=4e-4`, `lr_D=2e-3`, split 80%/20%.\n",
        "- Éval : KS test, histogrammes, QQ-plot, **nuage de courbes de prix**, **résumé statistique** (moyenne, std, skew, kurtosis, Sharpe, VaR, autocorr lag1, Ljung–Box sur r², max drawdown, CAGR).\n",
        "- Snapshots : trajectoires générées enregistrées pendant l'entraînement.\n",
        "\n",
        "> Astuce : si instabilité, baisse `lr_D` ou augmente `n_critic`. Réduis `batch_size` si mémoire GPU limite.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install (Colab recommandé)\n"
      ],
      "metadata": {
        "id": "4IciYmQYx_9W"
      },
      "id": "4IciYmQYx_9W"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9c8ccb32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c8ccb32",
        "outputId": "8abbcd3b-8bb3-4ec6-c336-44f0578ed0f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m124.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m124.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Si vous n'êtes pas sur Colab, adaptez les versions de torch à votre environnement.\n",
        "\n",
        "!pip -q install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip -q install scipy statsmodels matplotlib pandas numpy yfinance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports & Config"
      ],
      "metadata": {
        "id": "S_7lyWSByIWW"
      },
      "id": "S_7lyWSByIWW"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "65599332",
      "metadata": {
        "id": "65599332"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import ks_2samp, probplot, skew, kurtosis\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "\n",
        "class CFG:\n",
        "    ticker = \"^GSPC\"\n",
        "    start = \"1990-01-01\"\n",
        "    end = None  # jusqu'à aujourd'hui\n",
        "    seq_len = 64                # longueur des fenêtres\n",
        "    nz = 100                    # dimension du bruit\n",
        "    batch_size = 512            # réduisez si OOM\n",
        "    epochs = 150                # demandé : 150 (rapide). Mettre 2000 pour un entraînement long.\n",
        "    lr_G = 4e-4\n",
        "    lr_D = 1e-3                 # plus stable qu'un 2e-2 agressif sur RNN-GAN\n",
        "    n_critic = 8                # updates D par update G (WGAN-GP)\n",
        "    lambda_gp = 5.0            # gradient penalty\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    outdir = \"./rnn_gan_outputs\"\n",
        "    plot_epochs = [10, 50, 100, 150]  # snapshots pendant l'entraînement\n",
        "    use_ema = True              # utilise une EMA du générateur pour l'échantillonnage\n",
        "\n",
        "os.makedirs(CFG.outdir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Données : S&P 500 -> log-rendements"
      ],
      "metadata": {
        "id": "CfASJQa5yL5n"
      },
      "id": "CfASJQa5yL5n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7b31646b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b31646b",
        "outputId": "a1da5d9a-1c0d-44d6-f1b6-d710806d5fec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2335373881.py:4: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  raw = yf.download(CFG.ticker, start=CFG.start, end=CFG.end, progress=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observations totales: 8969 | Train: 7175 | Test: 1794\n",
            "mu(train)=0.000284, sigma(train)=0.011075\n"
          ]
        }
      ],
      "source": [
        "\n",
        "raw = yf.download(CFG.ticker, start=CFG.start, end=CFG.end, progress=False)\n",
        "close = raw[\"Close\"].dropna()\n",
        "log_price = np.log(close)\n",
        "rets = log_price.diff().dropna()\n",
        "\n",
        "# Split temporel 80/20 (pas de shuffle)\n",
        "split_idx = int(len(rets) * 0.8)\n",
        "train_rets = rets.iloc[:split_idx]\n",
        "test_rets  = rets.iloc[split_idx:]\n",
        "\n",
        "# Normalisation (stats d'entraînement uniquement, pour éviter toute fuite)\n",
        "mu, sigma = train_rets.mean(), train_rets.std()\n",
        "train_z = (train_rets - mu) / sigma\n",
        "test_z  = (test_rets - mu) / sigma\n",
        "\n",
        "print(f\"Observations totales: {len(rets)} | Train: {len(train_rets)} | Test: {len(test_rets)}\")\n",
        "print(f\"mu(train)={mu.iloc[0]:.6f}, sigma(train)={sigma.iloc[0]:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fenêtrage en séquences"
      ],
      "metadata": {
        "id": "W_c-H9pYyOkr"
      },
      "id": "W_c-H9pYyOkr"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a8d4f1b4",
      "metadata": {
        "id": "a8d4f1b4"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class SeqDataset(Dataset):\n",
        "    def __init__(self, series: pd.Series, seq_len: int):\n",
        "        self.x = series.values.astype(np.float32)\n",
        "        self.seq_len = seq_len\n",
        "        self.idxs = np.arange(0, len(self.x) - seq_len + 1)\n",
        "    def __len__(self):\n",
        "        return len(self.idxs)\n",
        "    def __getitem__(self, i):\n",
        "        idx = self.idxs[i]\n",
        "        window = self.x[idx: idx + self.seq_len]\n",
        "        return torch.from_numpy(window).unsqueeze(-1)  # (seq_len, 1)\n",
        "\n",
        "train_ds = SeqDataset(train_z, CFG.seq_len)\n",
        "train_dl = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=CFG.batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=2,                          # si souci, passer à 0\n",
        "    pin_memory=(CFG.device=='cuda'),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helpers"
      ],
      "metadata": {
        "id": "RQbVsVhDyRDk"
      },
      "id": "RQbVsVhDyRDk"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "01d15f9a",
      "metadata": {
        "id": "01d15f9a"
      },
      "outputs": [],
      "source": [
        "\n",
        "def ensure_3d(x, T=CFG.seq_len):\n",
        "    \"\"\"Force la forme (B, T, 1). Tolère (B,T), (B,T,1), (B,T,1,1).\"\"\"\n",
        "    if x.dim() == 4 and x.size(-1) == 1:\n",
        "        x = x.squeeze(-1)\n",
        "    if x.dim() == 2:\n",
        "        x = x.unsqueeze(-1)\n",
        "    if x.dim() != 3:\n",
        "        # Dernier recours : reshape plat -> (B, T, 1) si possible\n",
        "        B = x.size(0)\n",
        "        x = x.view(B, T, -1)\n",
        "        if x.size(-1) != 1:\n",
        "            x = x[..., :1]\n",
        "    return x\n",
        "\n",
        "def reconstruct_price(p0, rets):\n",
        "    \"\"\"Reconstruit une courbe de prix à partir de rendements log.\"\"\"\n",
        "    return p0 * np.exp(np.cumsum(rets))\n",
        "\n",
        "def max_drawdown(prices):\n",
        "    prices = np.asarray(prices, dtype=float)\n",
        "    run_max = np.maximum.accumulate(prices)\n",
        "    drawdown = prices / run_max - 1.0\n",
        "    return float(drawdown.min())\n",
        "\n",
        "def annualized_vol(returns, periods_per_year=252):\n",
        "    return float(np.std(returns, ddof=1) * np.sqrt(periods_per_year))\n",
        "\n",
        "def sharpe(returns, rf=0.0, periods_per_year=252):\n",
        "    ex = returns - rf / periods_per_year\n",
        "    sd = np.std(ex, ddof=1)\n",
        "    return float(np.mean(ex) / (sd + 1e-12) * np.sqrt(periods_per_year))\n",
        "\n",
        "def cagr(prices, periods_per_year=252):\n",
        "    return float((prices[-1] / prices[0]) ** (periods_per_year / len(prices)) - 1.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modèles : LSTM Generator & Critic (pooling temporel)"
      ],
      "metadata": {
        "id": "CpiqWUTmyU40"
      },
      "id": "CpiqWUTmyU40"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5fb97788",
      "metadata": {
        "id": "5fb97788"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LSTMGenerator(nn.Module):\n",
        "    def __init__(self, nz=100, hidden=64, num_layers=1, out_dim=1):\n",
        "        super().__init__()\n",
        "        self.nz = nz\n",
        "        self.lstm = nn.LSTM(input_size=nz, hidden_size=hidden, num_layers=num_layers, batch_first=True)\n",
        "        self.proj = nn.Linear(hidden, out_dim)\n",
        "    def forward(self, z):  # z: (B, T, nz)\n",
        "        h, _ = self.lstm(z)\n",
        "        out = self.proj(h)  # (B, T, 1)\n",
        "        return out\n",
        "\n",
        "class LSTMCritic(nn.Module):\n",
        "    def __init__(self, in_dim=1, hidden=64, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size=in_dim, hidden_size=hidden, num_layers=num_layers, batch_first=True)\n",
        "        self.head = nn.Linear(hidden, 1)\n",
        "    def forward(self, x):  # x: (B, T, 1)\n",
        "        x = ensure_3d(x)\n",
        "        h, _ = self.lstm(x)           # (B,T,H)\n",
        "        pooled = h.mean(dim=1)        # moyenne temporelle\n",
        "        score = self.head(pooled)\n",
        "        return score.squeeze(-1)\n",
        "\n",
        "def init_module(m):\n",
        "    if isinstance(m, (nn.Linear,)):\n",
        "        nn.init.orthogonal_(m.weight); nn.init.zeros_(m.bias)\n",
        "    if isinstance(m, nn.LSTM):\n",
        "        for name, p in m.named_parameters():\n",
        "            if \"weight\" in name: nn.init.orthogonal_(p)\n",
        "            elif \"bias\" in name: nn.init.zeros_(p)\n",
        "\n",
        "G = LSTMGenerator(nz=CFG.nz).to(CFG.device)\n",
        "D = LSTMCritic().to(CFG.device)\n",
        "G.apply(init_module); D.apply(init_module)\n",
        "\n",
        "# EMA pour G (optionnel)\n",
        "G_ema = None\n",
        "if CFG.use_ema:\n",
        "    G_ema = LSTMGenerator(nz=CFG.nz).to(CFG.device)\n",
        "    G_ema.load_state_dict(G.state_dict())\n",
        "    for p in G_ema.parameters(): p.requires_grad_(False)\n",
        "\n",
        "def ema_update(model, ema_model, decay=0.999):\n",
        "    if ema_model is None: return\n",
        "    with torch.no_grad():\n",
        "        for p, p_ema in zip(model.parameters(), ema_model.parameters()):\n",
        "            p_ema.copy_(decay*p_ema + (1-decay)*p)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimisation (WGAN-GP, TTUR)"
      ],
      "metadata": {
        "id": "ma4lsE4syXpJ"
      },
      "id": "ma4lsE4syXpJ"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KGaRZVGqyYNZ"
      },
      "id": "KGaRZVGqyYNZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d827bb39",
      "metadata": {
        "id": "d827bb39"
      },
      "outputs": [],
      "source": [
        "\n",
        "opt_G = torch.optim.Adam(G.parameters(), lr=CFG.lr_G, betas=(0.5, 0.9))\n",
        "opt_D = torch.optim.Adam(D.parameters(), lr=CFG.lr_D, betas=(0.5, 0.9))\n",
        "\n",
        "def gradient_penalty(D, real, fake):\n",
        "    real = ensure_3d(real)\n",
        "    fake = ensure_3d(fake)\n",
        "    B = real.size(0)\n",
        "    eps = torch.rand(B, 1, 1, device=real.device)\n",
        "    interp = eps * real + (1 - eps) * fake\n",
        "    interp.requires_grad_(True)\n",
        "\n",
        "    # Désactiver cuDNN pendant ce forward du Critic (double backward requis)\n",
        "    with torch.backends.cudnn.flags(enabled=False):\n",
        "        d_interp = D(interp)\n",
        "\n",
        "    grads = torch.autograd.grad(\n",
        "        outputs=d_interp,\n",
        "        inputs=interp,\n",
        "        grad_outputs=torch.ones_like(d_interp),\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True,\n",
        "    )[0]\n",
        "    grads = grads.view(B, -1)\n",
        "    gp = ((grads.norm(2, dim=1) - 1) ** 2).mean()\n",
        "    return gp\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_sequences(model, n_seq=8, seq_len=CFG.seq_len, nz=CFG.nz):\n",
        "    model.eval()\n",
        "    z = torch.randn(n_seq, seq_len, nz, device=CFG.device)\n",
        "    x_fake = model(z).squeeze(-1).detach().cpu().numpy()\n",
        "    return x_fake\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entraînement"
      ],
      "metadata": {
        "id": "AniOcMmgya25"
      },
      "id": "AniOcMmgya25"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "76199195",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76199195",
        "outputId": "58215371-1ba0-4cb9-e3ed-e53b1be9a2cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2460388987.py:6: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  p0_train = float(close.iloc[split_idx - 1])  # base price pour visualiser des prix pendant l'entraînement\n",
            "/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:825: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150 | D: 0.4126 | G: 0.1628\n",
            "Epoch 2/150 | D: -2.8589 | G: 1.7441\n",
            "Epoch 3/150 | D: -3.8901 | G: 2.1164\n",
            "Epoch 4/150 | D: -3.8552 | G: 2.7397\n",
            "Epoch 5/150 | D: -4.1879 | G: 3.6797\n",
            "Epoch 6/150 | D: -4.3392 | G: 1.9369\n",
            "Epoch 7/150 | D: -3.9729 | G: 1.9053\n",
            "Epoch 8/150 | D: -3.6351 | G: 1.9948\n",
            "Epoch 9/150 | D: -2.4980 | G: 3.1477\n",
            "Epoch 10/150 | D: -1.9288 | G: 5.6667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2460388987.py:50: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  samples_unscaled = samples * float(sigma) + float(mu)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/150 | D: -2.6211 | G: 6.1788\n",
            "Epoch 12/150 | D: -2.8310 | G: 6.1326\n",
            "Epoch 13/150 | D: -2.9944 | G: 8.1633\n",
            "Epoch 14/150 | D: -3.0740 | G: 8.8858\n",
            "Epoch 15/150 | D: -2.9711 | G: 8.3151\n",
            "Epoch 16/150 | D: -3.6607 | G: 8.8994\n",
            "Epoch 17/150 | D: -3.1597 | G: 9.1012\n",
            "Epoch 18/150 | D: -2.6937 | G: 9.4539\n",
            "Epoch 19/150 | D: -2.5901 | G: 10.1670\n",
            "Epoch 20/150 | D: -2.2264 | G: 10.7636\n",
            "Epoch 21/150 | D: -2.3435 | G: 10.3151\n",
            "Epoch 22/150 | D: -2.0709 | G: 12.4177\n",
            "Epoch 23/150 | D: -2.2086 | G: 12.4751\n",
            "Epoch 24/150 | D: -2.0540 | G: 13.0757\n",
            "Epoch 25/150 | D: -2.0142 | G: 12.9122\n",
            "Epoch 26/150 | D: -1.6411 | G: 13.3154\n",
            "Epoch 27/150 | D: -1.6941 | G: 13.1164\n",
            "Epoch 28/150 | D: -1.9086 | G: 12.7462\n",
            "Epoch 29/150 | D: -1.7806 | G: 13.3312\n",
            "Epoch 30/150 | D: -2.1999 | G: 12.9028\n",
            "Epoch 31/150 | D: -2.1134 | G: 13.4187\n",
            "Epoch 32/150 | D: -2.1283 | G: 12.7002\n",
            "Epoch 33/150 | D: -2.1940 | G: 13.8119\n",
            "Epoch 34/150 | D: -1.9706 | G: 13.4579\n",
            "Epoch 35/150 | D: -1.5385 | G: 13.3446\n",
            "Epoch 36/150 | D: -2.1546 | G: 14.0493\n",
            "Epoch 37/150 | D: -2.2499 | G: 14.6143\n",
            "Epoch 38/150 | D: -2.0497 | G: 13.6814\n",
            "Epoch 39/150 | D: -2.2213 | G: 14.0552\n",
            "Epoch 40/150 | D: -2.0226 | G: 15.0230\n",
            "Epoch 41/150 | D: -1.9956 | G: 14.4619\n",
            "Epoch 42/150 | D: -2.3018 | G: 14.4578\n",
            "Epoch 43/150 | D: -2.2843 | G: 15.2736\n",
            "Epoch 44/150 | D: -2.2983 | G: 14.2880\n",
            "Epoch 45/150 | D: -2.5168 | G: 15.3020\n",
            "Epoch 46/150 | D: -2.3192 | G: 16.1089\n",
            "Epoch 47/150 | D: -2.4377 | G: 15.4566\n",
            "Epoch 48/150 | D: -2.2244 | G: 16.2144\n",
            "Epoch 49/150 | D: -2.5035 | G: 16.5857\n",
            "Epoch 50/150 | D: -2.3435 | G: 15.7777\n",
            "Epoch 51/150 | D: -1.7426 | G: 16.1168\n",
            "Epoch 52/150 | D: -2.7506 | G: 16.7714\n",
            "Epoch 53/150 | D: -2.7004 | G: 16.7835\n",
            "Epoch 54/150 | D: -2.1447 | G: 16.8937\n",
            "Epoch 55/150 | D: -2.8145 | G: 16.9723\n",
            "Epoch 56/150 | D: -1.8788 | G: 17.1228\n",
            "Epoch 57/150 | D: -3.1040 | G: 17.6740\n",
            "Epoch 58/150 | D: -2.3668 | G: 16.6078\n",
            "Epoch 59/150 | D: -2.5168 | G: 17.4841\n",
            "Epoch 60/150 | D: -1.9939 | G: 17.7180\n",
            "Epoch 61/150 | D: -2.8276 | G: 17.4470\n",
            "Epoch 62/150 | D: -2.5783 | G: 18.2764\n",
            "Epoch 63/150 | D: -2.2805 | G: 17.4164\n",
            "Epoch 64/150 | D: -3.1948 | G: 17.8103\n",
            "Epoch 65/150 | D: -2.8759 | G: 18.0740\n",
            "Epoch 66/150 | D: -2.7558 | G: 17.9630\n",
            "Epoch 67/150 | D: -2.5036 | G: 16.8271\n",
            "Epoch 68/150 | D: -2.9812 | G: 17.1117\n",
            "Epoch 69/150 | D: -3.0700 | G: 17.9783\n",
            "Epoch 70/150 | D: -2.9617 | G: 17.1142\n",
            "Epoch 71/150 | D: -3.0925 | G: 17.9637\n",
            "Epoch 72/150 | D: -3.1281 | G: 17.8687\n",
            "Epoch 73/150 | D: -2.9441 | G: 18.5627\n",
            "Epoch 74/150 | D: -3.0838 | G: 18.1487\n",
            "Epoch 75/150 | D: -2.9298 | G: 17.7207\n",
            "Epoch 76/150 | D: -2.9017 | G: 18.1035\n",
            "Epoch 77/150 | D: -3.2759 | G: 18.2869\n",
            "Epoch 78/150 | D: -2.4828 | G: 17.9193\n",
            "Epoch 79/150 | D: -3.4742 | G: 17.5530\n",
            "Epoch 80/150 | D: -3.0928 | G: 17.3130\n",
            "Epoch 81/150 | D: -3.1003 | G: 18.1955\n",
            "Epoch 82/150 | D: -3.3852 | G: 18.7994\n",
            "Epoch 83/150 | D: -3.0777 | G: 18.9336\n",
            "Epoch 84/150 | D: -3.2172 | G: 19.0555\n",
            "Epoch 85/150 | D: -3.4238 | G: 18.0249\n",
            "Epoch 86/150 | D: -3.1902 | G: 18.7818\n",
            "Epoch 87/150 | D: -3.0679 | G: 19.0457\n",
            "Epoch 88/150 | D: -3.5331 | G: 18.9919\n",
            "Epoch 89/150 | D: -3.0966 | G: 18.4630\n",
            "Epoch 90/150 | D: -3.1823 | G: 18.4862\n",
            "Epoch 91/150 | D: -3.5363 | G: 18.7509\n",
            "Epoch 92/150 | D: -3.1768 | G: 19.4002\n",
            "Epoch 93/150 | D: -3.4016 | G: 18.9609\n",
            "Epoch 94/150 | D: -2.4874 | G: 18.5138\n",
            "Epoch 95/150 | D: -2.9656 | G: 18.9935\n",
            "Epoch 96/150 | D: -2.9974 | G: 19.1180\n",
            "Epoch 97/150 | D: -2.9391 | G: 18.8494\n",
            "Epoch 98/150 | D: -3.5381 | G: 18.7727\n",
            "Epoch 99/150 | D: -4.3838 | G: 19.6086\n",
            "Epoch 100/150 | D: -3.5031 | G: 19.1767\n",
            "Epoch 101/150 | D: -2.9891 | G: 18.9812\n",
            "Epoch 102/150 | D: -2.3456 | G: 18.5781\n",
            "Epoch 103/150 | D: -3.2306 | G: 20.3644\n",
            "Epoch 104/150 | D: 2.9329 | G: 21.9232\n",
            "Epoch 105/150 | D: -3.1653 | G: 19.4916\n",
            "Epoch 106/150 | D: -3.3882 | G: 20.4712\n",
            "Epoch 107/150 | D: -4.1642 | G: 19.6997\n",
            "Epoch 108/150 | D: -3.2506 | G: 19.2298\n",
            "Epoch 109/150 | D: -3.5535 | G: 20.4003\n",
            "Epoch 110/150 | D: -3.4157 | G: 19.8243\n",
            "Epoch 111/150 | D: -3.2814 | G: 20.3393\n",
            "Epoch 112/150 | D: -3.7465 | G: 19.9319\n",
            "Epoch 113/150 | D: -3.1998 | G: 20.5341\n",
            "Epoch 114/150 | D: -3.8013 | G: 19.7015\n",
            "Epoch 115/150 | D: -3.6512 | G: 19.6468\n",
            "Epoch 116/150 | D: -2.8962 | G: 20.3683\n",
            "Epoch 117/150 | D: -3.5659 | G: 20.6732\n",
            "Epoch 118/150 | D: -3.2202 | G: 20.2016\n",
            "Epoch 119/150 | D: -3.6104 | G: 20.4392\n",
            "Epoch 120/150 | D: -3.0952 | G: 20.7630\n",
            "Epoch 121/150 | D: -4.0189 | G: 20.5698\n",
            "Epoch 122/150 | D: -3.6845 | G: 21.0323\n",
            "Epoch 123/150 | D: -3.3915 | G: 20.1425\n",
            "Epoch 124/150 | D: -3.5097 | G: 20.2903\n",
            "Epoch 125/150 | D: -3.5658 | G: 20.4408\n",
            "Epoch 126/150 | D: -3.5237 | G: 20.2811\n",
            "Epoch 127/150 | D: -3.4082 | G: 20.4716\n",
            "Epoch 128/150 | D: -3.7771 | G: 19.6819\n",
            "Epoch 129/150 | D: -3.9860 | G: 19.9494\n",
            "Epoch 130/150 | D: -4.4416 | G: 21.1038\n",
            "Epoch 131/150 | D: -3.5486 | G: 20.5340\n",
            "Epoch 132/150 | D: -4.1596 | G: 20.6778\n",
            "Epoch 133/150 | D: -3.9856 | G: 20.8484\n",
            "Epoch 134/150 | D: -3.4768 | G: 20.5210\n",
            "Epoch 135/150 | D: -3.7163 | G: 20.3485\n",
            "Epoch 136/150 | D: -4.0217 | G: 20.4192\n",
            "Epoch 137/150 | D: -4.0108 | G: 21.1030\n",
            "Epoch 138/150 | D: -3.6224 | G: 20.9819\n",
            "Epoch 139/150 | D: -4.0235 | G: 21.3982\n",
            "Epoch 140/150 | D: -3.9024 | G: 21.1341\n",
            "Epoch 141/150 | D: -3.4700 | G: 19.3937\n",
            "Epoch 142/150 | D: -3.8781 | G: 21.3354\n",
            "Epoch 143/150 | D: -3.7429 | G: 21.3800\n",
            "Epoch 144/150 | D: -3.9328 | G: 20.9699\n",
            "Epoch 145/150 | D: -4.0749 | G: 21.3368\n",
            "Epoch 146/150 | D: -4.0938 | G: 20.5941\n",
            "Epoch 147/150 | D: -4.0725 | G: 21.3145\n",
            "Epoch 148/150 | D: -4.1924 | G: 20.7677\n",
            "Epoch 149/150 | D: -3.9844 | G: 21.1869\n",
            "Epoch 150/150 | D: -3.6713 | G: 20.6426\n",
            "Entraînement terminé en 28.6 min. Dernières pertes — D: -3.671, G: 20.643\n"
          ]
        }
      ],
      "source": [
        "\n",
        "loss_log = []\n",
        "start_time = time.time()\n",
        "p0_train = float(close.iloc[split_idx - 1])  # base price pour visualiser des prix pendant l'entraînement\n",
        "\n",
        "for epoch in range(1, CFG.epochs + 1):\n",
        "    G.train(); D.train()\n",
        "    for x_real in train_dl:\n",
        "        x_real = ensure_3d(x_real.to(CFG.device))\n",
        "\n",
        "        # --- Update D (n_critic fois) ---\n",
        "        for _ in range(CFG.n_critic):\n",
        "            z = torch.randn(x_real.size(0), CFG.seq_len, CFG.nz, device=CFG.device)\n",
        "            x_fake = G(z).detach()\n",
        "            d_real = D(x_real)\n",
        "            d_fake = D(x_fake)\n",
        "            gp = gradient_penalty(D, x_real, x_fake)\n",
        "            loss_D = -(d_real.mean() - d_fake.mean()) + CFG.lambda_gp * gp\n",
        "\n",
        "            opt_D.zero_grad()\n",
        "            loss_D.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(D.parameters(), 5.0)\n",
        "            opt_D.step()\n",
        "\n",
        "        # --- Update G ---\n",
        "        z = torch.randn(x_real.size(0), CFG.seq_len, CFG.nz, device=CFG.device)\n",
        "        x_fake = G(z)\n",
        "        d_fake = D(x_fake)\n",
        "        loss_G = -d_fake.mean()\n",
        "\n",
        "        opt_G.zero_grad()\n",
        "        loss_G.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(G.parameters(), 5.0)\n",
        "        opt_G.step()\n",
        "\n",
        "        if CFG.use_ema:\n",
        "            ema_update(G, G_ema)\n",
        "\n",
        "    loss_log.append((epoch, float(loss_D.detach().cpu()), float(loss_G.detach().cpu())))\n",
        "    print(f\"Epoch {epoch}/{CFG.epochs} | D: {loss_log[-1][1]:.4f} | G: {loss_log[-1][2]:.4f}\")\n",
        "\n",
        "    # Snapshots : courbes de rendements + prix synthétiques\n",
        "    if epoch in set(CFG.plot_epochs) or epoch % 50 == 0 or epoch == CFG.epochs:\n",
        "        with torch.no_grad():\n",
        "            model_for_samples = G_ema if (CFG.use_ema and G_ema is not None) else G\n",
        "            samples = sample_sequences(model_for_samples, n_seq=8)\n",
        "            # Convertit en rendements \"réels\"\n",
        "            samples_unscaled = samples * float(sigma) + float(mu)\n",
        "            # Reconstruit des prix\n",
        "            price_paths = [reconstruct_price(p0_train, s) for s in samples_unscaled]\n",
        "\n",
        "        # Plot rendements\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        for s in samples: plt.plot(s, alpha=0.8)\n",
        "        plt.title(f\"Trajectoires de rendements (normalisés) — Epoch {epoch}\")\n",
        "        plt.xlabel(\"t\"); plt.ylabel(\"r normalisés\")\n",
        "        plt.grid(True, alpha=0.3); plt.tight_layout()\n",
        "        plt.savefig(os.path.join(CFG.outdir, f\"samples_returns_epoch_{epoch}.png\")); plt.close()\n",
        "\n",
        "        # Plot prix\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        for s in price_paths: plt.plot(s, alpha=0.8)\n",
        "        plt.title(f\"Trajectoires de prix synthétiques — Epoch {epoch}\")\n",
        "        plt.xlabel(\"t\"); plt.ylabel(\"Prix\")\n",
        "        plt.grid(True, alpha=0.3); plt.tight_layout()\n",
        "        plt.savefig(os.path.join(CFG.outdir, f\"samples_prices_epoch_{epoch}.png\")); plt.close()\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "print(f\"Entraînement terminé en {elapsed/60:.1f} min. Dernières pertes — D: {loss_log[-1][1]:.3f}, G: {loss_log[-1][2]:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Évaluation : KS test, histogrammes, QQ-plot"
      ],
      "metadata": {
        "id": "HSIJbZLyydYl"
      },
      "id": "HSIJbZLyydYl"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8607dab1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8607dab1",
        "outputId": "32be2635-11bb-4b9f-a52b-6a5173992511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KS test: statistic=0.1159, p-value=0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3531085603.py:12: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  fake_eval = fake_norm * float(sigma) + float(mu)                 # rendements \"réels\" (log)\n",
            "/tmp/ipython-input-3531085603.py:16: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  real_test_unscaled  = real_test * float(sigma) + float(mu)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Génère une séquence synthétique de la taille du test\n",
        "G.eval()\n",
        "model_for_eval = G_ema if (CFG.use_ema and G_ema is not None) else G\n",
        "\n",
        "with torch.no_grad():\n",
        "    T = len(test_z)\n",
        "    z = torch.randn(1, T, CFG.nz, device=CFG.device)\n",
        "    fake_norm = model_for_eval(z).squeeze().detach().cpu().numpy()   # rendements normalisés\n",
        "    fake_eval = fake_norm * float(sigma) + float(mu)                 # rendements \"réels\" (log)\n",
        "\n",
        "# 1D arrays\n",
        "real_test = np.asarray(test_z, dtype=np.float32).reshape(-1)\n",
        "real_test_unscaled  = real_test * float(sigma) + float(mu)\n",
        "fake_test_unscaled  = fake_eval.astype(np.float32).reshape(-1)[: real_test.size]\n",
        "\n",
        "# KS test (deux échantillons)\n",
        "ks_stat, pval = ks_2samp(real_test_unscaled, fake_test_unscaled)\n",
        "print(f\"KS test: statistic={ks_stat:.4f}, p-value={pval:.4f}\")\n",
        "\n",
        "# Histogrammes comparés\n",
        "plt.figure(figsize=(9, 5))\n",
        "plt.hist(real_test_unscaled, bins=80, alpha=0.6, density=True, label=\"Réel (test)\")\n",
        "plt.hist(fake_test_unscaled, bins=80, alpha=0.6, density=True, label=\"Synthétique\")\n",
        "plt.title(\"Histogramme des rendements — Réel vs Synthétique\")\n",
        "plt.xlabel(\"Rendement journalier\")\n",
        "plt.ylabel(\"Densité\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(CFG.outdir, \"hist_reel_vs_synth.png\"))\n",
        "plt.close()\n",
        "\n",
        "# QQ-plot contre normale\n",
        "plt.figure(figsize=(5,5))\n",
        "probplot(real_test_unscaled, dist=\"norm\", plot=plt)\n",
        "plt.title(\"QQ-plot (Réel vs Normale)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(CFG.outdir, \"qqplot_real_norm.png\"))\n",
        "plt.close()\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "probplot(fake_test_unscaled, dist=\"norm\", plot=plt)\n",
        "plt.title(\"QQ-plot (Synthétique vs Normale)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(CFG.outdir, \"qqplot_fake_norm.png\"))\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prix : reconstruction + comparaisons statistiques (réel vs synthétique)\n"
      ],
      "metadata": {
        "id": "JeUX3ZMWyhMX"
      },
      "id": "JeUX3ZMWyhMX"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b1b9227f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1b9227f",
        "outputId": "8474d56c-1d50-42cc-8a28-ad79395ca9fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3076087280.py:12: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  seq = seq_norm * float(sigma) + float(mu)                       # rendements log réels\n",
            "/tmp/ipython-input-3076087280.py:17: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
            "  p0 = float(close.iloc[split_idx - 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Résumé statistique (arrondi) :\n",
            "                       serie      mean       std      skew  kurt_excess  \\\n",
            "0                Réel (test)  0.000476  0.012720 -0.630139    14.638681   \n",
            "1  Synthétique (vol médiane)  0.000172  0.006494 -0.190256     0.950450   \n",
            "\n",
            "   sharpe_ann   vol_ann    VaR_95    VaR_99  autocorr_lag1  LBQ_p_r2_lag10  \\\n",
            "0    0.593558  0.201931 -0.018568 -0.035258      -0.155738        0.000000   \n",
            "1    0.419566  0.103092 -0.010741 -0.017781       0.008898        0.000041   \n",
            "\n",
            "   max_drawdown      CAGR  KS_statistic  KS_pvalue  \n",
            "0     -0.339250  0.129527      0.115942        0.0  \n",
            "1     -0.121176  0.042755      0.115942        0.0  \n",
            "Stats sauvegardées : ./rnn_gan_outputs/summary_stats.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Nuage de k trajectoires synthétiques sur la longueur du test\n",
        "k = 20\n",
        "T = len(test_z)\n",
        "fake_mat = []\n",
        "with torch.no_grad():\n",
        "    for _ in range(k):\n",
        "        z = torch.randn(1, T, CFG.nz, device=CFG.device)\n",
        "        seq_norm = model_for_eval(z).squeeze().detach().cpu().numpy()  # rendements normalisés\n",
        "        seq = seq_norm * float(sigma) + float(mu)                       # rendements log réels\n",
        "        fake_mat.append(seq)\n",
        "fake_mat = np.stack(fake_mat, axis=0)  # (k, T)\n",
        "\n",
        "# Reconstruit les prix réel et synthétiques à partir du dernier prix du train\n",
        "p0 = float(close.iloc[split_idx - 1])\n",
        "real_price = reconstruct_price(p0, real_test_unscaled)\n",
        "fake_prices = np.array([reconstruct_price(p0, f) for f in fake_mat])\n",
        "\n",
        "# === Plot : réel vs nuage de trajectoires synthétiques ===\n",
        "plt.figure(figsize=(10, 6))\n",
        "for fp in fake_prices:\n",
        "    plt.plot(fp, alpha=0.45, linewidth=1)\n",
        "plt.plot(real_price, linewidth=2.5, label=\"Réel (test)\")\n",
        "plt.title(\"Prix synthétiques vs prix réel — fenêtre de test\")\n",
        "plt.xlabel(\"t\")\n",
        "plt.ylabel(\"Prix\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(CFG.outdir, \"prices_real_vs_synth.png\"))\n",
        "plt.close()\n",
        "\n",
        "# Choisit une trajectoire synthétique \"typique\" (volatilité médiane)\n",
        "vols = [annualized_vol(f) for f in fake_mat]\n",
        "idx_med = int(np.argsort(vols)[len(vols)//2])\n",
        "fake_returns_typ = fake_mat[idx_med]\n",
        "fake_price_typ   = fake_prices[idx_med]\n",
        "\n",
        "def lbq_p_r2(returns, lag=10):\n",
        "    df = acorr_ljungbox(returns**2, lags=[lag], return_df=True)\n",
        "    return float(df[\"lb_pvalue\"].iloc[-1])\n",
        "\n",
        "# Tableau de stats : réel vs synthétique (rendements + prix)\n",
        "def summarize(returns, prices, name):\n",
        "    return {\n",
        "        \"serie\": name,\n",
        "        \"mean\": float(np.mean(returns)),\n",
        "        \"std\": float(np.std(returns, ddof=1)),\n",
        "        \"skew\": float(skew(returns)),\n",
        "        \"kurt_excess\": float(kurtosis(returns, fisher=True)),\n",
        "        \"sharpe_ann\": sharpe(returns),\n",
        "        \"vol_ann\": annualized_vol(returns),\n",
        "        \"VaR_95\": float(np.quantile(returns, 0.05)),\n",
        "        \"VaR_99\": float(np.quantile(returns, 0.01)),\n",
        "        \"autocorr_lag1\": float(pd.Series(returns).autocorr(1)),\n",
        "        \"LBQ_p_r2_lag10\": lbq_p_r2(returns, lag=10),\n",
        "        \"max_drawdown\": max_drawdown(prices),\n",
        "        \"CAGR\": cagr(prices),\n",
        "    }\n",
        "\n",
        "summary_df = pd.DataFrame([\n",
        "    summarize(real_test_unscaled, real_price, \"Réel (test)\"),\n",
        "    summarize(fake_returns_typ,   fake_price_typ, \"Synthétique (vol médiane)\"),\n",
        "])\n",
        "\n",
        "# Ajoute le KS déjà calculé pour info\n",
        "summary_df[\"KS_statistic\"] = [ks_stat, ks_stat]\n",
        "summary_df[\"KS_pvalue\"]    = [pval, pval]\n",
        "\n",
        "# Sauvegardes\n",
        "csv_path = os.path.join(CFG.outdir, \"summary_stats.csv\")\n",
        "summary_df.to_csv(csv_path, index=False)\n",
        "print(\"Résumé statistique (arrondi) :\")\n",
        "print(summary_df.round(6))\n",
        "\n",
        "# Histogramme des prix finaux (répartition des niveaux atteints)\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.hist([fp[-1] for fp in fake_prices], bins=40, alpha=0.7, density=True, label=\"Synthétique (prix final)\")\n",
        "plt.axvline(real_price[-1], linestyle=\"--\", label=\"Réel (prix final)\")\n",
        "plt.title(\"Distribution du prix final — Synthétique vs Réel\")\n",
        "plt.xlabel(\"Prix final\")\n",
        "plt.ylabel(\"Densité\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(CFG.outdir, \"final_price_distribution.png\"))\n",
        "plt.close()\n",
        "\n",
        "print(f\"Stats sauvegardées : {csv_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sauvegarde des pertes + courbes"
      ],
      "metadata": {
        "id": "ldhc_54DykUX"
      },
      "id": "ldhc_54DykUX"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "95dab6f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95dab6f8",
        "outputId": "8a88eba4-2329-4ce4-ba88-d06f74310f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pertes sauvegardées dans ./rnn_gan_outputs/losses.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "log_df = pd.DataFrame(loss_log, columns=[\"epoch\", \"loss_D\", \"loss_G\"])\n",
        "log_csv = os.path.join(CFG.outdir, \"losses.csv\")\n",
        "log_df.to_csv(log_csv, index=False)\n",
        "print(f\"Pertes sauvegardées dans {log_csv}\")\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(log_df[\"epoch\"], log_df[\"loss_D\"], label=\"D\")\n",
        "plt.plot(log_df[\"epoch\"], log_df[\"loss_G\"], label=\"G\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
        "plt.title(\"Pertes WGAN-GP\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(CFG.outdir, \"loss_curves.png\"))\n",
        "plt.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfb4262d",
      "metadata": {
        "id": "cfb4262d"
      },
      "source": [
        "\n",
        "## Notes\n",
        "- Si les figures sont trop bruitées, augmentez `n_critic` (p.ex. 7 ou 10) ou baissez `lr_D`.\n",
        "- Si `DataLoader` pose problème sous Windows, mettez `num_workers=0`.\n",
        "- Pour des échantillons plus lisses, gardez `use_ema=True` (l'échantillonnage utilise `G_ema`).\n",
        "- `batch_size` peut être réduit (p.ex. 128) si la mémoire GPU est limite.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}